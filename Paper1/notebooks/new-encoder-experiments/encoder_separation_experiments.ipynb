{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"encoder_separation_experiments.ipynb","provenance":[],"authorship_tag":"ABX9TyNzHrN9lk7mu5dD3bSQuiUP"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ia2niKZjkolY"},"source":["from google.colab import drive\r\n","drive.mount('/gdrive')\r\n","%cd \"/gdrive/My Drive/Causality-Experiments/Paper1/notebooks/new-encoder-experiments\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WOFbWu6gkv7S"},"source":["!python -m pip install -r \"../../requirements.txt\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9CC3krvqkxNU"},"source":["import sys\r\n","sys.path.append('../..')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dgB6Ulo-kx-3"},"source":["import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","\r\n","import numpy as np\r\n","from scipy import interpolate\r\n","\r\n","from pathlib import Path\r\n","import random\r\n","import tqdm.notebook as tqdm\r\n","from copy import deepcopy\r\n","from argparse import Namespace\r\n","import warnings\r\n","\r\n","%matplotlib inline\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns\r\n","sns.set()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uTNj_jCwkzbE"},"source":["sys.path.insert(1, str(Path(\"..\") / \"..\" / \"causal_meta\" / \"utils\"))\r\n","sys.path.insert(1, str(Path(\"..\") / \"..\" / \"causal_meta\" / \"modules\"))\r\n","\r\n","from causal_meta.utils.data_utils import RandomSplineSCM\r\n","import causal_meta.utils.train_utils as tu\r\n","from encoder import Rotor\r\n","from mdn import MDN, GMM, mdn_nll\r\n","from gmm import GaussianMixture"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BITQ408Ak0Wo"},"source":["SEED = 91023\r\n","torch.manual_seed(SEED)\r\n","np.random.seed(SEED)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OVadCJdgk1lV"},"source":["def normal(mean, std, N): \r\n","    return torch.normal(torch.ones(N).mul_(mean), torch.ones(N).mul_(std)).view(-1, 1)\r\n","\r\n","def normal_like(X): \r\n","    mean = X.mean()\r\n","    std = X.std()\r\n","    return normal(mean, std, X.size(0))\r\n","\r\n","def mlp(opt): \r\n","    if opt.NUM_MID_LAYERS == -1: \r\n","        return nn.Linear(opt.INP_DIM, opt.OUT_DIM)\r\n","    else:\r\n","        return nets.MLP(opt.INP_DIM, opt.OUT_DIM, opt.NUM_MID_LAYERS, \r\n","                        opt.CAPACITY, opt.INP_NOISE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6G-Lqp07k2rR"},"source":["def mdn(opt): \r\n","    return MDN(opt.CAPACITY, opt.NUM_COMPONENTS)\r\n","\r\n","def gmm(opt): \r\n","    return GaussianMixture(opt.GMM_NUM_COMPONENTS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X_TVT6l0k3gM"},"source":["def xcodergen(opt): \r\n","    # Make rotor\r\n","    return Rotor(opt.XCODER_INIT)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XGrofajelORF"},"source":["def plot_key(frames, key, show=True, label=None, name=None): \r\n","    its, vals = zip(*[(frame.iter_num, getattr(frame, key)) for frame in frames])\r\n","    if show:\r\n","        plt.figure()\r\n","    plt.plot(its, vals, label=label)\r\n","    if show:\r\n","        plt.xlabel(\"Iterations\")\r\n","        plt.ylabel(name if name is not None else key.title())\r\n","        plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kCycIFjflPHB"},"source":["def gradnan_filter(model): \r\n","    nan_found = False\r\n","    for p in model.parameters(): \r\n","        nan_mask = torch.isnan(p.grad.data)\r\n","        nan_found = bool(nan_mask.any().item())\r\n","        p.grad.data[nan_mask] = 0.\r\n","    return nan_found"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o6HjMrXLlQGj"},"source":["def marginal_nll(opt, inp, nll): \r\n","    model_g = gmm(opt)\r\n","    if opt.CUDA: \r\n","        model_g = model_g.cuda()\r\n","    model_g.fit(inp, n_iter=opt.EM_ITERS)\r\n","    with torch.no_grad():\r\n","        loss_marginal = nll(model_g(inp), inp)\r\n","    return loss_marginal"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ECtcS9UDlRC2"},"source":["def encoder_train_shared_regret(opt, model_x2y, model_y2x, scm, encoder, decoder, alpha): \r\n","    if opt.CUDA: \r\n","        model_x2y = model_x2y.cuda()\r\n","        model_y2x = model_y2x.cuda()\r\n","        encoder = encoder.cuda()\r\n","        decoder = decoder.cuda()\r\n","    encoder_optim = torch.optim.Adam(encoder.parameters(), opt.ENCODER_LR)\r\n","    alpha_optim = torch.optim.Adam([alpha], opt.ALPHA_LR)\r\n","    frames = []\r\n","\r\n","    for meta_iter in tqdm.trange(opt.NUM_META_ITER): \r\n","        # Preheat the models\r\n","        _ = tu.train_nll(opt, model_x2y, scm, opt.TRAIN_DISTRY, 'X2Y', \r\n","                         mdn_nll, decoder, encoder)\r\n","        _ = tu.train_nll(opt, model_y2x, scm, opt.TRAIN_DISTRY, 'Y2X', \r\n","                         mdn_nll, decoder, encoder)\r\n","\r\n","        # Sample from SCM\r\n","        X = opt.TRANS_DISTRY()\r\n","        Y = scm(X)\r\n","        if opt.CUDA: \r\n","            X, Y = X.cuda(), Y.cuda()\r\n","        # Decode \r\n","        with torch.no_grad():\r\n","            X, Y = decoder(X, Y)\r\n","        # Encode\r\n","        X, Y = encoder(X, Y)\r\n","        with torch.no_grad():\r\n","            if opt.USE_BASELINE:\r\n","                baseline_y = marginal_nll(opt, Y, mdn_nll)\r\n","                baseline_x = marginal_nll(opt, X, mdn_nll)\r\n","            else:\r\n","                baseline_y = 0.\r\n","                baseline_x = 0.\r\n","        # Save state dicts\r\n","        state_x2y = deepcopy(model_x2y.state_dict())\r\n","        state_y2x = deepcopy(model_y2x.state_dict())\r\n","        # Inner loop \r\n","        optim_x2y = torch.optim.Adam(model_x2y.parameters(), lr=opt.FINETUNE_LR)\r\n","        optim_y2x = torch.optim.Adam(model_y2x.parameters(), lr=opt.FINETUNE_LR)\r\n","        regrets_x2y = []\r\n","        regrets_y2x = []\r\n","        is_nan = False\r\n","        # Evaluate regret discrepancy \r\n","        for t in range(opt.FINETUNE_NUM_ITER):\r\n","            loss_x2y = mdn_nll(model_x2y(X), Y)\r\n","            loss_y2x = mdn_nll(model_y2x(Y), X)\r\n","            if torch.isnan(loss_x2y).item() or torch.isnan(loss_y2x).item(): \r\n","                is_nan = True\r\n","                break\r\n","            optim_x2y.zero_grad()\r\n","            optim_y2x.zero_grad()\r\n","            loss_x2y.backward(retain_graph=True) \r\n","            loss_y2x.backward(retain_graph=True)\r\n","            # Filter out NaNs that might have sneaked in\r\n","            nan_in_x2y = gradnan_filter(model_x2y)\r\n","            nan_in_y2x = gradnan_filter(model_y2x)\r\n","            if nan_in_x2y or nan_in_y2x: \r\n","                is_nan = True\r\n","                break\r\n","            optim_x2y.step()\r\n","            optim_y2x.step()\r\n","            # Store for encoder\r\n","            regrets_x2y.append(loss_x2y + baseline_x)\r\n","            regrets_y2x.append(loss_y2x + baseline_y)\r\n","        if not is_nan:\r\n","            # Evaluate total regret\r\n","            regret_x2y = torch.stack(regrets_x2y).mean()\r\n","            regret_y2x = torch.stack(regrets_y2x).mean()\r\n","            # Evaluate losses\r\n","            loss = torch.logsumexp(\r\n","                torch.stack([F.logsigmoid(alpha) + regret_x2y,\r\n","                             F.logsigmoid(-alpha) + regret_y2x]), \r\n","                0)\r\n","            # Optimize\r\n","            encoder_optim.zero_grad()\r\n","            alpha_optim.zero_grad()\r\n","            loss.backward()\r\n","            # Make sure no nans\r\n","            if torch.isnan(encoder.theta.grad.data).any(): \r\n","                encoder.theta.grad.data.zero_()\r\n","            if torch.isnan(alpha.grad.data).any(): \r\n","                alpha.grad.data.zero_()\r\n","            encoder_optim.step()\r\n","            alpha_optim.step()\r\n","            # Load original state dicts\r\n","            model_x2y.load_state_dict(state_x2y)\r\n","            model_y2x.load_state_dict(state_y2x)\r\n","            # Add info\r\n","            frames.append(Namespace(iter_num=meta_iter, \r\n","                                    regret_x2y=regret_x2y.item(), \r\n","                                    regret_y2x=regret_y2x.item(),\r\n","                                    loss=loss.item(),\r\n","                                    alpha=alpha.item(), \r\n","                                    theta=encoder.theta.item()))\r\n","\r\n","        else:\r\n","            # Load original state dicts\r\n","            model_x2y.load_state_dict(state_x2y)\r\n","            model_y2x.load_state_dict(state_y2x)\r\n","            # Add dummy info\r\n","            if train_mode == 'theta':\r\n","                frames.append(Namespace(iter_num=meta_iter, \r\n","                                        regret_x2y=float('nan'), \r\n","                                        regret_y2x=float('nan'),\r\n","                                        loss=float('nan'),\r\n","                                        alpha=float('nan'), \r\n","                                        theta=float('nan')))\r\n","                \r\n","    return frames"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eqTnwqhOlRKi"},"source":["def plot_theta(frames, gt_theta, save=False): \r\n","    its, vals = zip(*[(frame.iter_num, frame.theta / (np.pi / 2)) for frame in frames])\r\n","    gt_theta = -gt_theta.item() / (np.pi / 2)\r\n","    plt.figure()\r\n","    # plt.plot(its, vals, label=r'$\\theta_{\\mathcal{E}}$', c='black')\r\n","    plt.plot(its, vals, label=r'$\\theta_{\\mathcal{E}}$')\r\n","    plt.plot(its, [gt_theta] * len(its), linestyle='--', label=r'Solution 1 $\\left(+\\frac{\\pi}{4}\\right)$')\r\n","    plt.plot(its, [gt_theta - 1] * len(its), linestyle='--', label=r'Solution 2 $\\left(-\\frac{\\pi}{4}\\right)$')\r\n","    plt.xlabel(\"Iterations\")\r\n","    plt.ylabel(\"Encoder Angle [π/2 rad]\")\r\n","    plt.legend()\r\n","    if save:\r\n","        plt.savefig('fixed-encoder-evo.pdf', bbox_inches='tight', format='pdf')\r\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MUd6S02FlSG6"},"source":["def probe_xcoders(encoder, decoder, init_y=.0):\r\n","    # Test encoder and decoder\r\n","    with torch.no_grad():\r\n","        _X = torch.tensor([[1.]])\r\n","        _Y = torch.tensor([[init_y]])\r\n","        if opt.CUDA:\r\n","            encoder.to('cuda')\r\n","            decoder.to('cuda')\r\n","            _X, _Y = _X.to('cuda'), _Y.to('cuda')\r\n","        _X_d, _Y_d = decoder(_X, _Y)\r\n","        _X_de, _Y_de = encoder(_X_d, _Y_d)\r\n","    print(f\"Initial (A, B) = {_X.item()}, {_Y.item()}\")\r\n","    print(f\"Decoded (X, Y) = {_X_d.item()}, {_Y_d.item()}\")\r\n","    print(f\"Encoded (U, V) = {_X_de.item()}, {_Y_de.item()}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MlDqcwAIla9i"},"source":["opt = Namespace()\r\n","\r\n","# Model\r\n","opt.CAPACITY = 32\r\n","opt.NUM_COMPONENTS = 10\r\n","opt.GMM_NUM_COMPONENTS = 10\r\n","\r\n","# Training\r\n","opt.LR = 0.01\r\n","opt.NUM_ITER = 20\r\n","opt.NUM_META_ITER = 1000\r\n","opt.ENCODER_LR = 0.01\r\n","opt.ALPHA_LR = 0.001\r\n","opt.CUDA = True\r\n","opt.REC_FREQ = 10\r\n","opt.ALPHA_INIT = 0.\r\n","opt.USE_BASELINE = True\r\n","\r\n","# Fine tuning\r\n","opt.FINETUNE_NUM_ITER = 5\r\n","opt.FINETUNE_LR = 0.001\r\n","opt.EM_ITERS = 500\r\n","\r\n","# Sampling \r\n","opt.NUM_SAMPLES = 1000\r\n","opt.TRAIN_DISTRY = lambda: normal(0, 2, opt.NUM_SAMPLES)\r\n","opt.TRANS_DISTRY = lambda: normal(np.random.uniform(-4, 4), \r\n","                                  2, opt.NUM_SAMPLES)\r\n","\r\n","# Encoder\r\n","opt.DECODER_DEFAULT = -float(0.5 * np.pi/2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wb-8sSFWl0uw"},"source":["# Rotation decoder/encoder"]},{"cell_type":"code","metadata":{"id":"LPDDjLDfldhG"},"source":["gt_decoder = Rotor(opt.DECODER_DEFAULT)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bRywk7QclrWu"},"source":["encoder = Rotor(0. * np.pi/2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xP3tE7VflsOX"},"source":["probe_xcoders(encoder, gt_decoder)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"puU3jp-OltPS"},"source":["alpha = tu.make_alpha(opt)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u-CJvWVHluIC"},"source":["model_x2y = mdn(opt)\r\n","model_y2x = mdn(opt)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G87OHRvElvGe"},"source":["with torch.autograd.detect_anomaly():\r\n","    frames = encoder_train_shared_regret(opt, model_x2y, model_y2x, rand_scm, encoder, gt_decoder, alpha)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_KfG3SQRlv6n"},"source":["plot_theta(frames, gt_decoder.theta)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YVrRyEzglw5E"},"source":["plot_key(frames, 'alpha', name='Structural Parameter')"],"execution_count":null,"outputs":[]}]}